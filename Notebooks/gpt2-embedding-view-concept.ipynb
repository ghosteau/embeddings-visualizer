{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9618af88-2b93-46f5-a516-c29cf3c6f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "from transformers import GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa0807e-08b8-4278-9495-5c80de022cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load GPT-2 tokenizer and model (smallest 'gpt2' base)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e6be3e-f819-48a3-b1c1-70600a0bf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Extract token embeddings: (vocab_size, embedding_dim)\n",
    "embeddings = model.get_input_embeddings().weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b93ca6-fb89-402d-8965-25aa8166da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Get token frequencies to select top N tokens (approximate by tokenizer vocab order)\n",
    "# Note: GPT-2 vocab is roughly ordered by frequency\n",
    "top_n = 3000\n",
    "selected_embeddings = embeddings[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4594a7e4-5fb4-417e-b5ef-e90c6b842963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Token texts for hover labels\n",
    "tokens = [tokenizer.decode([i]).strip() for i in range(top_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78ca040-5985-45c3-9288-40d2cc08fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Dimensionality reduction with UMAP\n",
    "warnings.filterwarnings(\"ignore\", message=\"n_jobs value 1 overridden\")\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='cosine', n_components=3, random_state=42)\n",
    "emb_3d = reducer.fit_transform(selected_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3939a06e-7a69-4a83-ba61-015a29fde3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Build interactive scatter plot with Plotly\n",
    "token_lengths = [len(tok) for tok in tokens]\n",
    "fig = px.scatter_3d(\n",
    "    x=emb_3d[:, 0],\n",
    "    y=emb_3d[:, 1],\n",
    "    z=emb_3d[:, 2],\n",
    "    hover_name=tokens,\n",
    "    color=token_lengths,\n",
    "    color_continuous_scale='Viridis',\n",
    "    opacity=0.7\n",
    ")\n",
    "\n",
    "# Make points smaller and sharper\n",
    "fig.update_traces(marker=dict(size=3, opacity=0.8))\n",
    "\n",
    "# Dark theme\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(showbackground=False),\n",
    "        yaxis=dict(showbackground=False),\n",
    "        zaxis=dict(showbackground=False)\n",
    "    ),\n",
    "    paper_bgcolor=\"black\",\n",
    "    plot_bgcolor=\"black\",\n",
    "    font_color=\"white\"\n",
    ")\n",
    "\n",
    "# Nice starting camera view\n",
    "fig.update_layout(scene_camera=dict(\n",
    "    eye=dict(x=1.5, y=1.5, z=1.5)\n",
    "))\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
